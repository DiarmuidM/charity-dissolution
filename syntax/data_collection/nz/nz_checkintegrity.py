# NZ Charity data - Check Integrity
# Alasdair Rutherford
# Created: 5 April 2018
# Last edited: Github history - https://github.com/DiarmuidM/mission_accomp/tree/master/syntax/data_collection/nz
# Edited by Tom Wallace

# Data guide: https://www.charities.govt.nz/charities-in-new-zealand/the-charities-register/open-data/

# Free text fields in the CSVs have sometimes not been coded properly with string quotes, leading
# to the commas in a freetext field being interpreted as new columns.  This puts some records out
# of sync.

# This script checks all the downloaded files, and records rows where this has occured.
# It does this by comparing the number of columns in a row to the number of columns
# in the first row (the variable names).

#######Import packages#######
import csv
import os
import sys
import re
sys.path.insert(0, './Functions_scripts') # Allows to set a different path for the scripts being called below (but only if it branches off of the root dir)
from downloaddate_function import downloaddate, longtime
from nz_rowfixer import row_fixer
from loggenerator import gen_log

#######Toggles#######
# Recomended settings - 'fix', True, True
# Action options are mutually exclusive
action = 'fix' # This can be toggled between 'fix' and 'mark'. Mark will put bad records in error file, fix will atempt to fix them first and put any still broken in an error file
cleanstart = True # This will delete any files generated by this script before it runs so subsequent runs have a fresh start
deleteempty = True # If this is true it will delete any integrity error file which is empty (i.e. there were no integrity errors)

#######Initialization#######
register = 'Organisations' 
grpannreturns = 'GrpOrgAllReturns'
activities = 'Activities'
area = 'AreaOfOperations'
beneficiaries = 'Beneficiaries'
group = 'Groups'
officers = 'Officers'
sectors = 'Sectors'
funds = 'SourceOfFunds'
vorgs = 'vOrganisations'
voff = 'vOfficerOrganisations'

log_starttime = longtime() # When the script starts for the logfile

# Run the downloaddate function to get the date
ddate = downloaddate()

# Path to save the downloaded data
datapath = './data_raw/' # Dropbox folder for project

print('_____________________________________________')

search = [activities, area, beneficiaries, group, sectors, funds, register, vorgs, officers] #[register] #
search_big = [voff, grpannreturns] #[] #

"""
# Open logfile
logfilepath = datapath + 'log_' + ddate + '.csv'
logfile = open(logfilepath, 'w', newline='')
logcsv = csv.writer(logfile)
logcsv.writerow(['timestamp', 'filename', 'url', 'downloaded', 'failedattempts'])
"""

#######Main Program#######

if cleanstart == True: # Deletes existing integrity files to ensure clean start
	for direct in search+search_big:
		for filename in os.listdir(datapath + '/' + direct): # Get all the file names
			if 'integrity.csv' in filename: # If they have 'integrity' in them delete them
				os.remove(datapath + '/' + direct + '/' + filename)
	print('>>> Clean start, integrity files deleted <<<\n')

# Check integrity of all listed datasets
processedfiles=[]
writtenfiles=[]

for data in search + search_big:
	print('CSV - Whole files 	|	Record type:', data) # Header for clarity in console output

	directory = datapath + '/' + data

	with open(os.path.join(directory, 'nz_' + data + '_errors_integrity.csv'), 'w', newline='', encoding='utf-8') as outCSVfile: # This opens the error file. By making this end with 'integrity' it can be a csv and not break the itertation because the if statement below picks it up and excludes it, before it had to be a txt written as a csv
		writtenfiles.append(os.path.join(directory, 'nz_' + data + '_errors_integrity.csv'))
		writer = csv.writer(outCSVfile)
		firstpass = 1
		# This for loop goes through all the files in each directory
		for filename in os.listdir(directory):

			#The long line of and "and not's" below are required to stop the integrity checker processing files it doens't need to, which slows it down.
			#First it is stopped from processing it's own output files
			#Then _yrerror which is produced by GrpOrgAllReturns and vOfficerOrganisations and already contains integrity checking
			#Then the broken up files for GrpOrgAllReturns and vOfficerOrganisations which are combined by nz_regroupfilesbyyear.py which is a previous step
			#Nethier GrpOrgAllReturns or vOfficerOrganisations have any integrity errors becasue they are removed in nz_regroupfilesbyyear.py but the integrity checker is still run on them to get them in the same file name format as the other files which are used in further steps. They could just be renamed but might as well process them.
			#The regex for the GrpOrgAllReturns or vOfficerOrganisations just says find the files with 4 numbers (e.g. 2010), a month number (e.g. 12), and a piece number (e.g. 3)
			if filename.endswith(".csv") and not(filename.endswith("_integrity.csv")) and not(filename.endswith("_yrerror.csv")) and not(re.search('^nz_GrpOrgAllReturns_y\d\d\d\d_m\d+_p\d.csv$', filename)) and not(re.search('^nz_vOfficerOrganisations_y\d\d\d\d_m\d+_p\d.csv$', filename)) and not(filename.endswith("_geog.csv")):
				with open(os.path.join(directory, filename), 'r', newline='', encoding='utf-8') as inCSVfile: # This opens each data file to be read
					print(os.path.join(directory, filename))
					processedfiles.append(os.path.join(directory, filename))
					reader = csv.reader(inCSVfile) # Read in each input file
					fieldnames = next(reader)
					checklength = len(fieldnames) # Check the correct length

					filename = filename.replace('.csv', '') # Strip the .csv off of the filename so the integrity file doens't have the extension embedded

					with open(os.path.join(directory, filename + '_integrity.csv'), 'w', newline='', encoding='utf-8') as integCSVfile: # This opens the new clean file
						writtenfiles.append(os.path.join(directory, filename + '_integrity.csv'))
						writerinteg = csv.writer(integCSVfile) # Define the writer
						writerinteg.writerow(fieldnames) # Write the field names

						
						if action == 'fix': 
							for row in reader: # For every row if each data file
								out_row, fixed = row_fixer(row, checklength)
								if fixed==True:
									writerinteg.writerow(out_row)
								else:
									if firstpass==1:
										writer.writerow(fieldnames)
										firstpass=0
									writer.writerow(out_row)
									print('>>> Error not fixed <<<')

						# If the fix is causing issues then this block just puts anything the wrong length in the error files with no fixing 
						if action == 'mark':
							for row in reader: # For every row if each data file
								if len(row) == checklength: # If the row is the right legth just write it to the clean file
									writerinteg.writerow(row)
								else: # If it's wrong...
									if firstpass==1: # If it's the frist time write the headers
										writer.writerow(fieldnames)
									firstpass=0 # Not first pass if you reach here so set off
									writer.writerow(row) # Write to the error file
									print('Broken integrity')

			else:
				pass
		
	if deleteempty == True: # Deletes the erorrs file if there were no errors and it's empty
		inputfilepath = datapath + data + '/' + 'nz_' + data + '_errors_integrity.csv'
		with open(inputfilepath, 'rb') as file: # open each error file
			filedata = file.read()
			#print(filedata)
		if filedata == b'': # b'' means empty
			os.remove(inputfilepath) # Delete it
			print('Empty error file removed:',inputfilepath)


	print('-------------------------------------\n')

#Log generator
finishtime = longtime() # Get ending time
scriptname = os.path.basename(__file__) # Get the current scriptname as a variable
scriptpath = (os.path.dirname(os.path.realpath(__file__))) # Get the absolute dir the script is in
scriptdesc = 'This script .'
processedfiles = processedfiles # Get the input file details
writtenfiles = writtenfiles # Get list of created files
settings_toggles = {'action': action, 'cleanstart': cleanstart, 'deleteempty': deleteempty}
gen_log(log_starttime, finishtime, scriptname, scriptpath, scriptdesc, processedfiles, writtenfiles, str(settings_toggles)) # Pass info to log file generator

print('All done!')